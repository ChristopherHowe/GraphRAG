{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2fe78d",
   "metadata": {},
   "source": [
    "# Demonstration\n",
    "Basics of how vector encodings work, notice similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce30776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star wars begins on episode 4 with a jedi who must travel to a different planet\n",
      "22.31% - A long time ago in a galaxy far far away\n",
      "35.85% - There was a space ship floating with anakin on it\n",
      "9.22% - A farmer milks his cows\n",
      "5.74% - they actually were on his land\n",
      "-0.87% - When a phone falls down into a drain, something interesting happens\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "test_passages = [\n",
    "    \"A long time ago in a galaxy far far away\",\n",
    "    \"There was a space ship floating with anakin on it\",\n",
    "    \"A farmer milks his cows\",\n",
    "    \"they actually were on his land\",\n",
    "    \"When a phone falls down into a drain, something interesting happens\",\n",
    "]\n",
    "test_query = [\n",
    "    \"Star wars begins on episode 4 with a jedi who must travel to a different planet\"\n",
    "]\n",
    "\n",
    "passage_embeddings = model.encode(test_passages)\n",
    "query_embeddings = model.encode(test_query)\n",
    "\n",
    "# Compute the (cosine) similarity scores\n",
    "scores = model.similarity(query_embeddings, passage_embeddings) * 100\n",
    "\n",
    "# Print the test passages with their corresponding similarities\n",
    "print(test_query[0])\n",
    "for passage, score in zip(test_passages, scores.tolist()[0]):\n",
    "    print(f\"{round(score, 2)}% - {passage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4473b0",
   "metadata": {},
   "source": [
    "# Content vector embedding extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2663321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping creating collection; 'graphRAG' already exists.\n",
      "Creating embeddings from content\n",
      "adding embeddings to db\n",
      "embedding db is ready\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from qdrant import MyQdrant\n",
    "from db_funcs import get_all_content, get_db_con\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "size=len(model.encode(\"test\"))\n",
    "qdrant_client=MyQdrant(\"graphRAG\",size)\n",
    "conn=get_db_con()\n",
    "content_ids, content=get_all_content(conn.cursor())\n",
    "print(\"Creating embeddings from content\")\n",
    "content_embeddings=model.encode(content)\n",
    "print(\"adding embeddings to db\")\n",
    "qdrant_client.add_points(content_embeddings, content_ids)\n",
    "print(\"embedding db is ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
