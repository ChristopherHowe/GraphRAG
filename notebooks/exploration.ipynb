{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8d6dc7",
   "metadata": {},
   "source": [
    "# Exploratory Notebook\n",
    "Contains a whole bunch of code where I tested various things out, left as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf62c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/GraphRAG/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to /home/chris/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "from db_funcs import get_all_content, get_db_con\n",
    "import dotenv\n",
    "from utils import Sentence_Extractor\n",
    "from neo4j_funcs import Neo4j_Driver\n",
    "from utils import jupyter_print_paragraph\n",
    "from EntityRelationshipExtractor import ER_Extractor\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "neo4j = Neo4j_Driver()\n",
    "sentence_extractor = Sentence_Extractor()\n",
    "er_extractor=ER_Extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fdc30f",
   "metadata": {},
   "source": [
    "# Dataset Visualization\n",
    "Provide some statistics on content sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a32b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 802.61\n",
      "Maximum length: 4063\n",
      "Minimum length: 169\n",
      "Standard deviation: 359.58\n",
      "\n",
      "Sample of lengths: [1576, 338, 771, 815, 1585, 1008, 565, 531, 599, 517, 407, 845, 545, 534, 609, 1049, 545, 576, 520, 531]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "with get_db_con().cursor() as cur:\n",
    "    content_ids, all_content = get_all_content(cur)\n",
    "content_lengths = [len(content) for content in all_content]\n",
    "\n",
    "print(f\"Average length: {np.mean(content_lengths):.2f}\")\n",
    "print(f\"Maximum length: {max(content_lengths)}\")\n",
    "print(f\"Minimum length: {min(content_lengths)}\")\n",
    "print(f\"Standard deviation: {np.std(content_lengths):.2f}\")\n",
    "print(f\"\\nSample of lengths: {random.sample(content_lengths, min(20, len(content_lengths)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0fbea",
   "metadata": {},
   "source": [
    "# Sentence vs Paragraph Entity Relationship Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a815b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Paragraph:\n",
      "\n",
      "Since all modern ctenophores except the beroids have cydippid-like larvae, it ha\n",
      "s widely been assumed that their last common ancestor also resembled cydippids, \n",
      "having an egg-shaped body and a pair of retractable tentacles. Richard Harbison'\n",
      "s purely morphological analysis in 1985 concluded that the cydippids are not mon\n",
      "ophyletic, in other words do not contain all and only the descendants of a singl\n",
      "e common ancestor that was itself a cydippid. Instead he found that various cydi\n",
      "ppid families were more similar to members of other ctenophore orders than to ot\n",
      "her cydippids. He also suggested that the last common ancestor of modern ctenoph\n",
      "ores was either cydippid-like or beroid-like. A molecular phylogeny analysis in \n",
      "2001, using 26 species, including 4 recently discovered ones, confirmed that the\n",
      " cydippids are not monophyletic and concluded that the last common ancestor of m\n",
      "odern ctenophores was cydippid-like. It also found that the genetic differences \n",
      "between these species were very small – so small that the relationships between \n",
      "the Lobata, Cestida and Thalassocalycida remained uncertain. This suggests that \n",
      "the last common ancestor of modern ctenophores was relatively recent, and perhap\n",
      "s was lucky enough to survive the Cretaceous–Paleogene extinction event 65.5 mil\n",
      "lion years ago while other lineages perished. When the analysis was broadened to\n",
      " include representatives of other phyla, it concluded that cnidarians are probab\n",
      "ly more closely related to bilaterians than either group is to ctenophores but t\n",
      "hat this diagnosis is uncertain.\n",
      "\n",
      "Entity relationships extracted from sentences individually:\n",
      "beroid -- parent taxon -> ctenophore\n",
      "monophyletic -- studied by -> morphological analysis\n",
      "families -- part of -> orders\n",
      "cydippid -- parent taxon -> ctenophore\n",
      "beroid -- parent taxon -> ctenophore\n",
      "molecular phylogeny -- opposite of -> monophyletic\n",
      "Lobata -- parent taxon -> Cestida\n",
      "Cretaceous–Paleogene extinction event -- event distance -> 65.5\n",
      "ctenophores -- parent taxon -> bilaterian\n",
      "\n",
      "Entity relationships extracted from the entire paragraph:\n",
      "cydippid -- instance of -> monophyletic\n",
      "cydippid -- instance of -> monophyletic\n",
      "cydippid -- instance of -> monophyletic\n",
      "cydippid -- instance of -> monophyletic\n"
     ]
    }
   ],
   "source": [
    "# test paragraph or sentence entity relationships\n",
    "with get_db_con().cursor() as cur:\n",
    "    content_ids, all_content = get_all_content(cur)\n",
    "random_paragraph = random.choice(all_content)\n",
    "sentences = sentence_extractor.get_sentences(random_paragraph)\n",
    "\n",
    "# Entity extraction on each sentence individually\n",
    "individual_triplets = []\n",
    "for sentence in sentences:\n",
    "    triplets = er_extractor.extract_ERs([sentence])\n",
    "    individual_triplets.extend(triplets)\n",
    "\n",
    "# Entity extraction on the entire paragraph as one\n",
    "paragraph_triplets = er_extractor.extract_ERs([random_paragraph])\n",
    "\n",
    "# Print results\n",
    "print(\"Random Paragraph:\\n\")\n",
    "jupyter_print_paragraph(random_paragraph)\n",
    "print(\"\\nEntity relationships extracted from sentences individually:\")\n",
    "for triplet in individual_triplets:\n",
    "    print(f\"{triplet.head} -- {triplet.type} -> {triplet.tail}\")\n",
    "\n",
    "print(\"\\nEntity relationships extracted from the entire paragraph:\")\n",
    "for triplet in paragraph_triplets:\n",
    "    print(f\"{triplet.head} -- {triplet.type} -> {triplet.tail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1432b8",
   "metadata": {},
   "source": [
    "# Basic Sentence Encoding Example\n",
    "Demonstrates how sentance encoding works and what kind of values this system outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58811c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "test_passages = [\n",
    "    \"A long time ago in a galaxy far far away\",\n",
    "    \"There was a space ship floating with anakin on it\",\n",
    "    \"A farmer milks his cows\",\n",
    "    \"they actually were on his land\",\n",
    "    \"When a phone falls down into a drain, something interesting happens\",\n",
    "]\n",
    "test_query = [\n",
    "    \"Star wars begins on episode 4 with a jedi who must travel to a different planet\"\n",
    "]\n",
    "\n",
    "passage_embeddings = model.encode(test_passages)\n",
    "query_embeddings = model.encode(test_query)\n",
    "\n",
    "# Compute the (cosine) similarity scores\n",
    "scores = model.similarity(query_embeddings, passage_embeddings) * 100\n",
    "\n",
    "# Print the test passages with their corresponding similarities\n",
    "print(test_query[0])\n",
    "for passage, score in zip(test_passages, scores.tolist()[0]):\n",
    "    print(f\"{round(score, 2)}% - {passage}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
